{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поиск токсичных комментариев на сайте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "\n",
    "**План выполнеия работы**\n",
    "\n",
    "1. Загрузить и подготовить данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "-----------------------------------------------------------------\n",
      "Дубликатов - 0\n",
      "-----------------------------------------------------------------\n",
      "Пропусков:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "toxic         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "Соотношение в целевом признаке:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(comments.head(5))\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "comments.info()\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "\n",
    "print('Дубликатов -', comments.duplicated().sum())\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "\n",
    "print('Пропусков:')\n",
    "display(comments.isna().sum())\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "\n",
    "print('Соотношение в целевом признаке:')\n",
    "display(comments.toxic.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы:\n",
    "\n",
    "- В таблице 159 292 объектов. \n",
    "- Пропусков нет, явных дубликатов нет. \n",
    "- Тексты комментариев на английском, есть лишние знаки типа \"\\nMore\\n \n",
    "- В целевом признаке 90% объектов отрицательного класса, то есть в дальнейшем нужно будет учесть это \n",
    "\n",
    "Необходимо избавиться от столбца Unnamed, так как он фактически дублирует индексы  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаляю столбец Unnamed:\n",
    "comments = comments.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция очищения текстов постов:\n",
    "def clear_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)   \n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.19 s, sys: 23.3 ms, total: 4.22 s\n",
      "Wall time: 4.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#очищаю тексты постов:\n",
    "comments['text'] = comments['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  d aww he matches this background colour i m se...      0\n",
       "2  hey man i m really not trying to edit war it s...      0\n",
       "3  more i can t make any real suggestions on impr...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция РОS-тэгирования слов:\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,               #прилагательное\n",
    "                \"N\": wordnet.NOUN,              #существительное\n",
    "                \"V\": wordnet.VERB,              #глагол\n",
    "                \"R\": wordnet.ADV                #наречие\n",
    "               }  \n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#ввожу функцию леммализации тектов постов:\n",
    "def lemm_text(text):\n",
    "    text = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 6s, sys: 1min 25s, total: 18min 31s\n",
      "Wall time: 18min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#леммализирую тексты постов:\n",
    "comments['text'] = comments['text'].apply(lemm_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits make under my userna...      0\n",
       "1  d aww he match this background colour i m seem...      0\n",
       "2  hey man i m really not try to edit war it s ju...      0\n",
       "3  more i can t make any real suggestion on impro...      0\n",
       "4  you sir be my hero any chance you remember wha...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим выборки в соотношении 80/10/10:\n",
    "features = comments.drop(['toxic'], axis=1) \n",
    "target = comments.toxic\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, \n",
    "                                                                              target, \n",
    "                                                                              test_size=.2, \n",
    "                                                                              random_state=12345)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, \n",
    "                                                                            target_valid, \n",
    "                                                                            test_size=.5,\n",
    "                                                                            random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127433, 1)\n",
      "(127433,)\n",
      "(15929, 1)\n",
      "(15929,)\n",
      "(15930, 1)\n",
      "(15930,)\n"
     ]
    }
   ],
   "source": [
    "#смотрим размеры выборок:\n",
    "for i in [features_train, target_train, features_valid, target_valid, features_test, target_test]:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля значений 1 в тренировочной выборке: 0.10166911239631807\n"
     ]
    }
   ],
   "source": [
    "#смотрю соотношение 1/0 в выборках на примере target_train:\n",
    "indices_1 = [i for i,x in enumerate(target_train) if x == 1]\n",
    "count_1 = len(indices_1)\n",
    "\n",
    "indices_0 = [i for i,x in enumerate(target_train) if x == 0]\n",
    "count_0 = len(indices_0)\n",
    "\n",
    "print('Доля значений 1 в тренировочной выборке:', len(indices_1) / (len(indices_1) + len(indices_0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#уменьшаю кол-во 0 в выборках train:\n",
    "\n",
    "comments_train = comments.iloc[target_train.index]\n",
    "target_train_0 = comments_train[comments_train['toxic'] == 0]['toxic']\n",
    "target_train_1 = comments_train[comments_train['toxic'] == 1]['toxic']\n",
    "\n",
    "\n",
    "target_train_0_resample = target_train_0.sample(target_train_1.shape[0], random_state=12345)\n",
    "target_train_resample = pd.concat([target_train_0_resample, target_train_1])\n",
    "\n",
    "features_train_resample = comments.iloc[target_train_resample.index]\n",
    "\n",
    "features_train_resample, target_train_resample = shuffle(features_train_resample,\n",
    "                                                         target_train_resample,\n",
    "                                                         random_state=12345)\n",
    "\n",
    "features_train_resample = features_train_resample.text \n",
    "\n",
    "print('Соотношение 1/0 в тренировочной выборке:')\n",
    "print(target_train_resample.value_counts(normalize=True))\n",
    "print()\n",
    "print(features_train_resample.shape)\n",
    "print(target_train_resample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы:\n",
    "    \n",
    "- Удален ненужный столбец\n",
    "- Очищены тексты комментариев от ненужных знаков\n",
    "- Тексты леммализированы\n",
    "- Убраны стоп-слова\n",
    "- Сбалансированы данные в целевом признаке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_train.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 логистической регрессии = 0.76\n",
      "при параметрах {'lr__C': 5, 'lr__class_weight': 'balanced', 'lr__max_iter': 200, 'lr__random_state': 12345, 'lr__solver': 'lbfgs'}\n",
      "\n",
      "CPU times: user 14min 17s, sys: 9min 17s, total: 23min 35s\n",
      "Wall time: 23min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english', sublinear_tf=True)), \n",
    "                     (\"lr\", LogisticRegression())])\n",
    "    \n",
    "parameters = {'lr__solver': ('liblinear', 'saga','newton-cg', 'lbfgs'),\n",
    "              'lr__C': (.1, 1, 5, 10),\n",
    "              'lr__random_state': ([12345]),\n",
    "              'lr__max_iter': ([200]),\n",
    "              'lr__class_weight': (['balanced'])} \n",
    "                                                  \n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train, target_train)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "lr_train_f1 = max(mts)\n",
    "\n",
    "print('F1 логистической регрессии =', round(lr_train_f1,2))\n",
    "print('при параметрах', gscv.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 логистической регрессии на валидации = 0.76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#валидация:\n",
    "predictions_valid = gscv.predict(features_valid.text)\n",
    "lr_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 логистической регрессии на валидации =', round(lr_valid_f1,2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 дерева решений = 0.63\n",
      "при параметрах {'dtc__class_weight': 'balanced', 'dtc__max_depth': 24, 'dtc__random_state': 12345}\n",
      "\n",
      "F1 дерева решений на валидации = 0.63\n",
      "\n",
      "CPU times: user 12min 25s, sys: 8.31 s, total: 12min 34s\n",
      "Wall time: 12min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"dtc\", DecisionTreeClassifier())])\n",
    "    \n",
    "parameters = {'dtc__max_depth': ([x for x in range(1, 25)]),\n",
    "              'dtc__random_state': ([12345]), \n",
    "              'dtc__class_weight': (['balanced'])}\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train, target_train)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "dtc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 дерева решений =', round(dtc_train_f1,2))\n",
    "print('при параметрах', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "#валидация:\n",
    "predictions_valid = gscv.predict(features_valid.text)\n",
    "dtc_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 дерева решений на валидации =', round(dtc_valid_f1,2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 CatBoostClassifier = 0.74\n",
      "при параметрах {'cbc__class_weights': (1, 1), 'cbc__iterations': 200, 'cbc__verbose': False}\n",
      "\n",
      "F1 CatBoostClassifier на валидации = 0.76\n",
      "\n",
      "CPU times: user 38min 43s, sys: 9min 36s, total: 48min 20s\n",
      "Wall time: 48min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"cbc\", CatBoostClassifier())])\n",
    "    \n",
    "parameters = {'cbc__verbose': ([False]),\n",
    "              'cbc__iterations': ([200]),\n",
    "              'cbc__class_weights':([(1, 1), (1, 11)])} \n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train, target_train)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "cbc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 CatBoostClassifier =', round(cbc_train_f1,2))\n",
    "print('при параметрах', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "#валидация:\n",
    "predictions_valid = gscv.predict(features_valid.text)\n",
    "cbc_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 CatBoostClassifier на валидации =', round(cbc_valid_f1,2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 случайного леса = 0.39\n",
      "при параметрах {'rfc__class_weight': 'balanced', 'rfc__criterion': 'entropy', 'rfc__max_depth': 6, 'rfc__n_estimators': 24, 'rfc__random_state': 12345}\n",
      "\n",
      "F1 случайного леса на валидации = 0.28\n",
      "\n",
      "CPU times: user 51min 20s, sys: 26.4 s, total: 51min 46s\n",
      "Wall time: 51min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"rfc\", RandomForestClassifier())])\n",
    "    \n",
    "parameters = {'rfc__n_estimators': ([x for x in range(10, 30)]),\n",
    "              'rfc__random_state': ([12345]),\n",
    "              'rfc__max_depth': ([x for x in range(1, 10)]),\n",
    "              'rfc__criterion': (['entropy']),\n",
    "              'rfc__class_weight': (['balanced'])}\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train, target_train)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "rfc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 случайного леса =', round(rfc_train_f1,2))\n",
    "print('при параметрах', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "#валидация:\n",
    "predictions_valid = gscv.predict(features_valid.text)\n",
    "rfc_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 случайного леса на валидации =', round(rfc_valid_f1,2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 SGDClassifier = 0.75\n",
      "при параметрах {'clf__class_weight': 'balanced', 'clf__eta0': 0.1, 'clf__learning_rate': 'adaptive', 'clf__loss': 'modified_huber', 'clf__random_state': 12345}\n",
      "\n",
      "F1 SGDClassifier на валидации = 0.75\n",
      "\n",
      "CPU times: user 14min 50s, sys: 18.6 s, total: 15min 8s\n",
      "Wall time: 15min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"clf\", SGDClassifier())])\n",
    "    \n",
    "parameters = {'clf__loss': ('hinge', 'log', 'modified_huber'),\n",
    "              'clf__learning_rate': ('constant', 'optimal', 'invscaling', 'adaptive'),\n",
    "              'clf__eta0': (.01, .05, .1, .5),\n",
    "              'clf__random_state': ([12345]),\n",
    "              'clf__class_weight': (['balanced'])}\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train, target_train)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "sgdc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 SGDClassifier =', round(sgdc_train_f1,2))\n",
    "print('при параметрах', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "#валидация:\n",
    "predictions_valid = gscv.predict(features_valid.text)\n",
    "sgdc_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 SGDClassifier на валидации =', round(sgdc_valid_f1,2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор модели для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 на обучающей выборке</th>\n",
       "      <th>F1 на валидационной выборке</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.756144</td>\n",
       "      <td>0.764114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.736849</td>\n",
       "      <td>0.759040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.745703</td>\n",
       "      <td>0.746437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.626301</td>\n",
       "      <td>0.631981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.394852</td>\n",
       "      <td>0.280101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        F1 на обучающей выборке  F1 на валидационной выборке\n",
       "LogisticRegression                     0.756144                     0.764114\n",
       "CatBoostClassifier                     0.736849                     0.759040\n",
       "SGDClassifier                          0.745703                     0.746437\n",
       "DecisionTreeClassifier                 0.626301                     0.631981\n",
       "RandomForestClassifier                 0.394852                     0.280101"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cводная таблица по показателям F1, времени обучения модели и времени предсказания модели:\n",
    "index = ['LogisticRegression',\n",
    "         'DecisionTreeClassifier',\n",
    "         'CatBoostClassifier',\n",
    "         'RandomForestClassifier',\n",
    "         'SGDClassifier'\n",
    "        ]\n",
    "\n",
    "data = {'F1 на обучающей выборке': [lr_train_f1,\n",
    "                                    dtc_train_f1,\n",
    "                                    cbc_train_f1,\n",
    "                                    rfc_train_f1,\n",
    "                                    sgdc_train_f1],\n",
    "        \n",
    "        'F1 на валидационной выборке': [lr_valid_f1,\n",
    "                                        dtc_valid_f1,\n",
    "                                        cbc_valid_f1,\n",
    "                                        rfc_valid_f1,\n",
    "                                        sgdc_valid_f1]}\n",
    "\n",
    "f1_data = pd.DataFrame(data=data, index=index)\n",
    "\n",
    "f1_data.sort_values(by='F1 на валидационной выборке', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наилучшей моделью является LogisticRegression, которая на валидационной выборке показала F1 = 0.76. Применим её для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальный F1 логистической регрессии = 0.75\n"
     ]
    }
   ],
   "source": [
    "#тестирование лучшей модели:\n",
    "predictions_test = gscv.predict(features_test.text)\n",
    "lr_test_f1 = f1_score(target_test, predictions_test)\n",
    "print('Финальный F1 логистической регрессии =', round(lr_test_f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы:\n",
    "\n",
    "- Данные загружены и проведена их предобработка - удаление лишних данных, очистка текстов, лемматизация.\n",
    "\n",
    "- Обучены 5 моделей с разными гиперпараметрами и выборками и проведена проверка их на тестовой выборке.\n",
    "\n",
    "- Выбрана лучшая модель по показателю F1. Худшими показателями среди моделей обладают RandomForestClassifier и DecisionTreeClassifier, так как дали наименьшее F1.\n",
    "\n",
    "- Наилучшей моделью стала LogisticRegression, которая на тестировании показала F1 = 0.75. "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 430,
    "start_time": "2024-03-14T15:27:28.749Z"
   },
   {
    "duration": 2636,
    "start_time": "2024-03-14T15:27:51.450Z"
   },
   {
    "duration": 983,
    "start_time": "2024-03-14T15:28:02.643Z"
   },
   {
    "duration": 317,
    "start_time": "2024-03-14T15:29:27.675Z"
   },
   {
    "duration": 11,
    "start_time": "2024-03-14T15:34:38.508Z"
   },
   {
    "duration": 4,
    "start_time": "2024-03-14T15:35:06.028Z"
   },
   {
    "duration": 432,
    "start_time": "2024-03-14T15:35:23.444Z"
   },
   {
    "duration": 431,
    "start_time": "2024-03-14T15:35:53.878Z"
   },
   {
    "duration": 1021,
    "start_time": "2024-03-14T15:35:54.311Z"
   },
   {
    "duration": 330,
    "start_time": "2024-03-14T15:35:55.334Z"
   },
   {
    "duration": 17,
    "start_time": "2024-03-14T15:35:55.666Z"
   },
   {
    "duration": 8,
    "start_time": "2024-03-14T15:35:55.685Z"
   },
   {
    "duration": 4658,
    "start_time": "2024-03-14T15:35:55.695Z"
   },
   {
    "duration": 946,
    "start_time": "2024-03-14T15:36:00.354Z"
   },
   {
    "duration": 8,
    "start_time": "2024-03-14T16:01:07.567Z"
   },
   {
    "duration": 89,
    "start_time": "2024-03-14T16:01:29.167Z"
   },
   {
    "duration": 1125,
    "start_time": "2024-03-14T16:02:29.287Z"
   },
   {
    "duration": 4,
    "start_time": "2024-03-14T16:02:32.361Z"
   },
   {
    "duration": 964,
    "start_time": "2024-03-14T16:02:32.368Z"
   },
   {
    "duration": 316,
    "start_time": "2024-03-14T16:02:33.334Z"
   },
   {
    "duration": 10,
    "start_time": "2024-03-14T16:02:33.652Z"
   },
   {
    "duration": 18,
    "start_time": "2024-03-14T16:02:33.665Z"
   },
   {
    "duration": 4781,
    "start_time": "2024-03-14T16:02:33.685Z"
   },
   {
    "duration": 6,
    "start_time": "2024-03-14T16:02:38.468Z"
   },
   {
    "duration": 5,
    "start_time": "2024-03-14T16:02:38.482Z"
   },
   {
    "duration": 943,
    "start_time": "2024-03-14T16:02:38.490Z"
   },
   {
    "duration": 573,
    "start_time": "2024-03-14T16:03:58.447Z"
   },
   {
    "duration": 1500,
    "start_time": "2024-03-14T16:10:25.979Z"
   },
   {
    "duration": 1067,
    "start_time": "2024-03-14T16:10:27.481Z"
   },
   {
    "duration": 323,
    "start_time": "2024-03-14T16:10:28.550Z"
   },
   {
    "duration": 11,
    "start_time": "2024-03-14T16:10:28.882Z"
   },
   {
    "duration": 10,
    "start_time": "2024-03-14T16:10:28.895Z"
   },
   {
    "duration": 4877,
    "start_time": "2024-03-14T16:10:28.906Z"
   },
   {
    "duration": 7,
    "start_time": "2024-03-14T16:10:33.785Z"
   },
   {
    "duration": 6,
    "start_time": "2024-03-14T16:10:33.794Z"
   },
   {
    "duration": 148,
    "start_time": "2024-03-14T16:10:33.802Z"
   },
   {
    "duration": 1430,
    "start_time": "2024-03-15T12:56:34.708Z"
   },
   {
    "duration": 2385,
    "start_time": "2024-03-15T12:56:36.140Z"
   },
   {
    "duration": 298,
    "start_time": "2024-03-15T12:56:38.526Z"
   },
   {
    "duration": 10,
    "start_time": "2024-03-15T12:56:38.825Z"
   },
   {
    "duration": 5,
    "start_time": "2024-03-15T12:56:38.837Z"
   },
   {
    "duration": 4365,
    "start_time": "2024-03-15T12:56:38.858Z"
   },
   {
    "duration": 7,
    "start_time": "2024-03-15T12:56:43.225Z"
   },
   {
    "duration": 15,
    "start_time": "2024-03-15T12:56:43.234Z"
   },
   {
    "duration": 521,
    "start_time": "2024-03-15T12:56:43.258Z"
   },
   {
    "duration": 1171154,
    "start_time": "2024-03-15T12:56:43.781Z"
   },
   {
    "duration": 7,
    "start_time": "2024-03-15T13:16:14.937Z"
   },
   {
    "duration": 36,
    "start_time": "2024-03-15T13:20:55.182Z"
   },
   {
    "duration": 4,
    "start_time": "2024-03-15T13:21:30.150Z"
   },
   {
    "duration": 40,
    "start_time": "2024-03-15T13:21:47.470Z"
   },
   {
    "duration": 49,
    "start_time": "2024-03-15T13:22:05.439Z"
   },
   {
    "duration": 3,
    "start_time": "2024-03-15T13:24:17.247Z"
   },
   {
    "duration": 8,
    "start_time": "2024-03-15T13:49:29.587Z"
   },
   {
    "duration": 6,
    "start_time": "2024-03-15T13:49:59.372Z"
   },
   {
    "duration": 1472667,
    "start_time": "2024-03-15T13:50:06.972Z"
   },
   {
    "duration": 121188,
    "start_time": "2024-03-15T14:16:20.210Z"
   },
   {
    "duration": 546474,
    "start_time": "2024-03-15T14:18:21.400Z"
   },
   {
    "duration": 598121,
    "start_time": "2024-03-15T14:27:27.875Z"
   },
   {
    "duration": 184427,
    "start_time": "2024-03-15T14:37:25.997Z"
   },
   {
    "duration": 11,
    "start_time": "2024-03-15T14:40:30.426Z"
   },
   {
    "duration": 1419,
    "start_time": "2024-03-16T13:16:56.467Z"
   },
   {
    "duration": 3272,
    "start_time": "2024-03-16T13:16:57.888Z"
   },
   {
    "duration": 301,
    "start_time": "2024-03-16T13:17:01.161Z"
   },
   {
    "duration": 18,
    "start_time": "2024-03-16T13:17:01.463Z"
   },
   {
    "duration": 31,
    "start_time": "2024-03-16T13:17:01.483Z"
   },
   {
    "duration": 4368,
    "start_time": "2024-03-16T13:17:01.516Z"
   },
   {
    "duration": 7,
    "start_time": "2024-03-16T13:17:05.885Z"
   },
   {
    "duration": 13,
    "start_time": "2024-03-16T13:17:05.893Z"
   },
   {
    "duration": 629,
    "start_time": "2024-03-16T13:17:05.908Z"
   },
   {
    "duration": 1138946,
    "start_time": "2024-03-16T13:17:06.539Z"
   },
   {
    "duration": 7,
    "start_time": "2024-03-16T13:36:05.488Z"
   },
   {
    "duration": 48,
    "start_time": "2024-03-16T13:36:05.496Z"
   },
   {
    "duration": 3,
    "start_time": "2024-03-16T13:36:05.545Z"
   },
   {
    "duration": 49,
    "start_time": "2024-03-16T13:36:05.551Z"
   },
   {
    "duration": 16,
    "start_time": "2024-03-16T13:36:05.601Z"
   },
   {
    "duration": 1444863,
    "start_time": "2024-03-16T13:36:05.619Z"
   },
   {
    "duration": 350,
    "start_time": "2024-03-16T14:00:10.484Z"
   },
   {
    "duration": 108,
    "start_time": "2024-03-16T14:00:10.835Z"
   },
   {
    "duration": 121,
    "start_time": "2024-03-16T14:00:10.945Z"
   },
   {
    "duration": 161,
    "start_time": "2024-03-16T14:00:11.068Z"
   },
   {
    "duration": 12,
    "start_time": "2024-03-16T14:00:11.231Z"
   },
   {
    "duration": 0,
    "start_time": "2024-03-16T14:00:11.244Z"
   },
   {
    "duration": 11,
    "start_time": "2024-03-16T14:07:18.466Z"
   },
   {
    "duration": 102,
    "start_time": "2024-03-16T14:08:10.124Z"
   },
   {
    "duration": 775716,
    "start_time": "2024-03-16T14:09:51.169Z"
   },
   {
    "duration": 2993093,
    "start_time": "2024-03-16T14:23:15.404Z"
   },
   {
    "duration": 3072502,
    "start_time": "2024-03-16T15:13:38.075Z"
   },
   {
    "duration": 917064,
    "start_time": "2024-03-16T16:05:38.842Z"
   },
   {
    "duration": 17,
    "start_time": "2024-03-16T16:28:01.847Z"
   },
   {
    "duration": 711,
    "start_time": "2024-03-16T16:35:05.511Z"
   },
   {
    "duration": 1430052,
    "start_time": "2024-03-16T16:35:11.041Z"
   },
   {
    "duration": 630,
    "start_time": "2024-03-16T16:59:23.273Z"
   },
   {
    "duration": 18,
    "start_time": "2024-03-16T16:59:32.973Z"
   },
   {
    "duration": 4,
    "start_time": "2024-03-16T17:00:38.026Z"
   },
   {
    "duration": 637,
    "start_time": "2024-03-16T17:00:49.044Z"
   },
   {
    "duration": 10,
    "start_time": "2024-03-16T17:01:29.223Z"
   },
   {
    "duration": 661,
    "start_time": "2024-03-16T17:02:08.369Z"
   },
   {
    "duration": 652,
    "start_time": "2024-03-16T17:04:41.331Z"
   },
   {
    "duration": 1389,
    "start_time": "2024-03-18T13:05:20.826Z"
   },
   {
    "duration": 3206,
    "start_time": "2024-03-18T13:05:22.216Z"
   },
   {
    "duration": 283,
    "start_time": "2024-03-18T13:05:25.423Z"
   },
   {
    "duration": 9,
    "start_time": "2024-03-18T13:05:25.707Z"
   },
   {
    "duration": 16,
    "start_time": "2024-03-18T13:05:25.718Z"
   },
   {
    "duration": 4228,
    "start_time": "2024-03-18T13:05:25.735Z"
   },
   {
    "duration": 7,
    "start_time": "2024-03-18T13:05:29.964Z"
   },
   {
    "duration": 10,
    "start_time": "2024-03-18T13:05:29.972Z"
   },
   {
    "duration": 478,
    "start_time": "2024-03-18T13:05:29.983Z"
   },
   {
    "duration": 1111975,
    "start_time": "2024-03-18T13:05:30.462Z"
   },
   {
    "duration": 7,
    "start_time": "2024-03-18T13:24:02.440Z"
   },
   {
    "duration": 109,
    "start_time": "2024-03-18T13:24:02.448Z"
   },
   {
    "duration": 24,
    "start_time": "2024-03-18T13:24:02.558Z"
   },
   {
    "duration": 44,
    "start_time": "2024-03-18T13:24:02.585Z"
   },
   {
    "duration": 49,
    "start_time": "2024-03-18T13:24:02.630Z"
   },
   {
    "duration": 1415802,
    "start_time": "2024-03-18T13:24:02.681Z"
   },
   {
    "duration": 731,
    "start_time": "2024-03-18T13:47:38.485Z"
   },
   {
    "duration": 754508,
    "start_time": "2024-03-18T13:47:39.218Z"
   },
   {
    "duration": 2907601,
    "start_time": "2024-03-18T14:00:13.728Z"
   },
   {
    "duration": 3108338,
    "start_time": "2024-03-18T14:48:41.331Z"
   },
   {
    "duration": 909359,
    "start_time": "2024-03-18T15:40:29.670Z"
   },
   {
    "duration": 10,
    "start_time": "2024-03-18T15:55:39.030Z"
   },
   {
    "duration": 697,
    "start_time": "2024-03-18T15:55:39.042Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
